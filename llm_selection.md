# Выбор LLM для Code Explainer API

## Выбранная модель: CodeLlama 70B

### Почему именно CodeLlama 70B?

1. **Специализация на коде**: CodeLlama дообучена на 500 млрд токенов, связанных с программированием, поэтому отлично понимает логику и синтаксис разных языков.

2. **Открытый и бесплатный доступ**: В отличие от GPT-4 с платным API, CodeLlama полностью бесплатна для исследований и коммерческого использования, что идеально подходит образовательным проектам.

3. **Высокая точность**: CodeLlama 70B показывает 69,5% на бенчмарке HumanEval, обходя GPT-4 (67%) в ряде задач по программированию.

4. **Локальный запуск**: Модель можно запускать на собственном оборудовании или в облаке, сохраняя контроль над данными и временем отклика.

5. **Поддержка множества языков**: Более 80 языков программирования, включая Python, JavaScript, Java, C++ и другие.

### Подход к интеграции

Так как запуск CodeLlama 70B требует серьёзных ресурсов, мы используем гибридную схему:

1. **Основной вариант**: Hugging Face Inference API для CodeLlama (доступен бесплатный тариф).
2. **Резервный вариант**: Мок-сервис LLM для демонстрации.
3. **Перспектива**: Лёгкий переход на собственный инстанс CodeLlama.

### Рассматриваемые альтернативы

- **GPT-4**: Более высокая точность, но высокая стоимость ($0.06 за 1K токенов).
- **Claude 3**: Хорошие объяснения, но также платный API.
- **Llama 3.1 405B**: Лучшие результаты, но сложнее в развёртывании на своих мощностях.

CodeLlama 70B обеспечивает оптимальный баланс производительности, цены и доступности для сервиса объяснения кода.